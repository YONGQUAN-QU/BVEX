{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b0a5d2-2817-4547-9095-4b968ec8fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "import tensorflow_datasets as tfds\n",
    "import sys\n",
    "from flax import optim\n",
    "sys.path.append('/workspace/yquai/BVEX/DL/')\n",
    "from bvex_dl import *\n",
    "from namelist_dl import *\n",
    "sys.path.append('/workspace/yquai/BVEX/DL/DL_Model/CNN/')\n",
    "sys.path.append('/workspace/yquai/BVEX/DL/DL_Model/')\n",
    "from model import PeriodicCNN\n",
    "from flax import serialization\n",
    "from copy import deepcopy\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "import time as Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e55c7f-1ba6-44bf-a89a-0c426cbcb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = optax.exponential_decay(init_value=0.00001, transition_steps=10,decay_rate=0.8,transition_begin=0,staircase=True, end_value=0.00001)\n",
    "\n",
    "\n",
    "def create_train_state(rng, learning_rate, pretrained):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    cnn = PeriodicCNN()\n",
    "    \n",
    "    if pretrained == None:\n",
    "        params = cnn.init(rng, jnp.ones([1, 64, 64, 3]))['params']\n",
    "    else:\n",
    "        params = pretrained\n",
    "        \n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=cnn.apply, params=params, tx=tx)\n",
    "\n",
    "def get_datasets(batch_size):\n",
    "    ds_builder = tfds.builder('observation_history')\n",
    "#    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train[:95%]', batch_size=batch_size, shuffle_files=True))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='train[95%:]', batch_size=batch_size, shuffle_files=True))\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893ec51c-3111-469f-9330-38c0edfb3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def accumulate_mse(params):\n",
    "        \n",
    "        batch['states'] = jnp.transpose(batch['states'], axes=[0,1,3,2,4])\n",
    "        \n",
    "        stateNow = batch['states'][:,0,:,:,:]\n",
    "        qNow = batch['states'][:,0,:,:,0]\n",
    "        tNow = batch['time'][:, 0]\n",
    "        \n",
    "        qNew, tNew= vetdrk4(qNow, tNow)\n",
    "        pNew, _, _ = laplacian(qNew)\n",
    "        fNew = jax.vmap(cal_forcing)(pNew, tNew)\n",
    "        \n",
    "        stateNew = jnp.stack((qNew, pNew, fNew), axis=-1)\n",
    "        \n",
    "        del fNew\n",
    "        del pNew\n",
    "        \n",
    "        correction = PeriodicCNN().apply({'params': params}, stateNew).squeeze()\n",
    "        \n",
    "\n",
    "        del stateNew\n",
    "        \n",
    "        qNewCorrected = qNew + correction.squeeze()\n",
    "                \n",
    "        del qNew\n",
    "        \n",
    "        for i in range(1, 40):\n",
    "            \n",
    "            qNew, tNew = vetdrk4(qNewCorrected, tNew)\n",
    "            pNew, _, _ = laplacian(qNew)\n",
    "            fNew = jax.vmap(cal_forcing)(pNew, tNew)\n",
    "        \n",
    "            stateNew = jnp.stack((qNew, pNew, fNew), axis=-1)\n",
    "            \n",
    "            del pNew\n",
    "            del fNew\n",
    "            \n",
    "            correction = PeriodicCNN().apply({'params': params}, stateNew).squeeze()\n",
    "\n",
    "            del stateNew\n",
    "            \n",
    "            qNewCorrected = qNew + correction.squeeze()\n",
    "            pNewCorrected, _, _ = laplacian(qNewCorrected)\n",
    "            \n",
    "            del qNew\n",
    "            \n",
    "        statesCorrected = jnp.stack((qNewCorrected, pNewCorrected), axis=-1)      \n",
    "        \n",
    "        loss = jnp.mean(optax.l2_loss(statesCorrected, batch['states'][:, 1, :, :, :2]))\n",
    "\n",
    "        for i in range(40, 80):\n",
    "            \n",
    "            qNew, tNew = vetdrk4(qNewCorrected, tNew)\n",
    "            pNew, _, _ = laplacian(qNew)\n",
    "            fNew = jax.vmap(cal_forcing)(pNew, tNew)\n",
    "        \n",
    "            stateNew = jnp.stack((qNew, pNew, fNew), axis=-1)\n",
    "            \n",
    "            del pNew\n",
    "            del fNew\n",
    "            \n",
    "            correction = PeriodicCNN().apply({'params': params}, stateNew).squeeze()\n",
    "\n",
    "            del stateNew\n",
    "            \n",
    "            qNewCorrected = qNew + correction.squeeze()\n",
    "            pNewCorrected, _, _ = laplacian(qNewCorrected)\n",
    "            \n",
    "            del qNew\n",
    "            \n",
    "        statesCorrected = jnp.stack((qNewCorrected, pNewCorrected), axis=-1)      \n",
    "        \n",
    "        loss += jnp.mean(optax.l2_loss(statesCorrected, batch['states'][:, 2, :, :, :2]))\n",
    "        \n",
    "        \n",
    "        return loss, statesCorrected\n",
    "\n",
    "\n",
    "    grad_fn = jax.value_and_grad(accumulate_mse, has_aux=True)\n",
    "    (loss, final_state), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    metrics = {\n",
    "        \"obs_loss\": loss,\n",
    "    }\n",
    "\n",
    "    \n",
    "    return state, metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "    def accumulate_mse(params):\n",
    "        \n",
    "        batch['states'] = jnp.transpose(batch['states'], axes=[0,1,3,2,4])\n",
    "        \n",
    "        stateNow = batch['states'][:,0,:,:,:]\n",
    "        qNow = batch['states'][:,0,:,:,0]\n",
    "        tNow = batch['time'][:, 0]\n",
    "        \n",
    "        qNew, tNew= vetdrk4(qNow, tNow)\n",
    "        pNew, _, _ = laplacian(qNew)\n",
    "        fNew = jax.vmap(cal_forcing)(pNew, tNew)\n",
    "        \n",
    "        stateNew = jnp.stack((qNew, pNew, fNew), axis=-1)\n",
    "        \n",
    "        del fNew\n",
    "        del pNew\n",
    "        \n",
    "        correction = PeriodicCNN().apply({'params': params}, stateNew).squeeze()\n",
    "        \n",
    "\n",
    "        del stateNew\n",
    "        \n",
    "        qNewCorrected = qNew + correction.squeeze()\n",
    "                \n",
    "        del qNew\n",
    "        \n",
    "        for i in range(1, 40):\n",
    "            \n",
    "            qNew, tNew = vetdrk4(qNewCorrected, tNew)\n",
    "            pNew, _, _ = laplacian(qNew)\n",
    "            fNew = jax.vmap(cal_forcing)(pNew, tNew)\n",
    "        \n",
    "            stateNew = jnp.stack((qNew, pNew, fNew), axis=-1)\n",
    "            \n",
    "            del pNew\n",
    "            del fNew\n",
    "            \n",
    "            correction = PeriodicCNN().apply({'params': params}, stateNew).squeeze()\n",
    "\n",
    "            del stateNew\n",
    "            \n",
    "            qNewCorrected = qNew + correction.squeeze()\n",
    "            pNewCorrected, _, _ = laplacian(qNewCorrected)\n",
    "            \n",
    "            del qNew\n",
    "            \n",
    "        statesCorrected = jnp.stack((qNewCorrected, pNewCorrected), axis=-1)      \n",
    "        \n",
    "        loss = jnp.mean(optax.l2_loss(statesCorrected, batch['states'][:, 1, :, :, :2]))\n",
    "        \n",
    "        for i in range(40, 80):\n",
    "            \n",
    "            qNew, tNew = vetdrk4(qNewCorrected, tNew)\n",
    "            pNew, _, _ = laplacian(qNew)\n",
    "            fNew = jax.vmap(cal_forcing)(pNew, tNew)\n",
    "        \n",
    "            stateNew = jnp.stack((qNew, pNew, fNew), axis=-1)\n",
    "            \n",
    "            del pNew\n",
    "            del fNew\n",
    "            \n",
    "            correction = PeriodicCNN().apply({'params': params}, stateNew).squeeze()\n",
    "\n",
    "            del stateNew\n",
    "            \n",
    "            qNewCorrected = qNew + correction.squeeze()\n",
    "            pNewCorrected, _, _ = laplacian(qNewCorrected)\n",
    "            \n",
    "            del qNew\n",
    "            \n",
    "        statesCorrected = jnp.stack((qNewCorrected, pNewCorrected), axis=-1)      \n",
    "        \n",
    "        loss += jnp.mean(optax.l2_loss(statesCorrected, batch['states'][:, 2, :, :, :2]))\n",
    "        \n",
    "\n",
    "        \n",
    "        return loss, statesCorrected\n",
    "\n",
    "\n",
    "    total_mse, final_states = accumulate_mse(params)\n",
    "    \n",
    "    \n",
    "    metrics = {\n",
    "        \"obs_loss\": total_mse,\n",
    "    }\n",
    "    \n",
    "    del total_mse\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    \n",
    "    batch_metrics = []\n",
    "    # 4 cycles per epoch\n",
    "  \n",
    "    \n",
    "    for batch in train_ds:\n",
    "        optimizer, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "        \n",
    "    training_batch_metrics = jax.device_get(batch_metrics)\n",
    "    \n",
    "    training_batch_metrics = training_batch_metrics[:-1]\n",
    "    \n",
    "    training_epoch_metrics = {\n",
    "        k: np.mean([metrics[k] for metrics in training_batch_metrics])\n",
    "        for k in training_batch_metrics[0]\n",
    "    }\n",
    "    \n",
    "    print('Training - epoch: %d, obs loss: %.4f,' \n",
    "          % (epoch,\n",
    "             training_epoch_metrics['obs_loss']))\n",
    "    \n",
    "    return optimizer, training_epoch_metrics\n",
    "\n",
    "\n",
    "def eval_model(params, test_ds):\n",
    "    \n",
    "    batch_metrics = []\n",
    "    for batch in test_ds:\n",
    "        metrics = eval_step(params, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "        \n",
    "    testing_batch_metrics = jax.device_get(batch_metrics)\n",
    "    \n",
    "    testing_batch_metrics = testing_batch_metrics[:-1]\n",
    "    \n",
    "    testing_metrics = {\n",
    "        k: np.mean([metrics[k] for metrics in testing_batch_metrics])\n",
    "        for k in testing_batch_metrics[0]\n",
    "    }\n",
    "\n",
    "    \n",
    "    print('Testing - epoch: %d,  obs_loss: %.4f'  \n",
    "          % (epoch,\n",
    "             testing_metrics['obs_loss'],\n",
    "))\n",
    "    \n",
    "    return testing_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03c3e37-f551-4de3-9bdd-3fa005623648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeriodicCNN\n",
    "loaded = np.load('/workspace/yquai/BVEX/DL/DL_Model/CNN/checkpoint/CNN16_state_dict_epoch_100.npy',allow_pickle=True).item()\n",
    "rng = jax.random.PRNGKey(2021)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "learning_rate = schedule\n",
    "state = create_train_state(init_rng, learning_rate, loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538aaced-8a1d-459b-9d98-18d28b6f0e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 4\n",
    "train_ds, test_ds = get_datasets(batch_size)\n",
    "weight= 0.0\n",
    "n_observation = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6a96f-a2c9-4c58-b271-22b7f0fa4ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - epoch: 1, obs loss: 0.0460,\n",
      "Time - 1320.9103543758392, LR - 9.999999747378752e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    start = Time.time()\n",
    "    state, train_metrics = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    end = Time.time()\n",
    "    print(f'Time - {end - start}, LR - {schedule(epoch)}')\n",
    "    eval_model(state.params, test_ds)\n",
    "    dict_output = serialization.to_state_dict(state.params)\n",
    "    np.save(f\"checkpoint/CNN16_o_{n_observation}_epoch_{epoch}.npy\", dict_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93eb454-b1f4-4bad-971e-c15201d9d89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
